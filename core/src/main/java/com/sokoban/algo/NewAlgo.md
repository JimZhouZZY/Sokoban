# 一些自己设想的新算法

---

## 随机路径长估计 RPLE

*这个算法是我自己想出来的一个随机算法，能够平衡效率与时间*

**随机路径长估计**适用于 IDA* 等算法的启发式函数

### 目的

在搜索算法中，启发式函数常常被设定为 `Box` 到 `BoxTarget` 的曼哈顿距离，然而这种启发式函数并不算精准

传统的路径长估计也不可行。例如，在每一次计算 `loss` 时，都使用 `A*` 算法进行路径长估计，就会造成本末倒置：

1. 作为离散问题，最优解往往不一定让箱子直接推入目标点，这只是局部最优而非全局最优
2. `A*` 把一个 $O(1)$ 的算法变成 $O(k^n)$，造成算法的瓶颈，这是不可接受的

因此，这里提出**随机路径估计**的算法进行路径的估计

### 算法内容

算法需要一段时间的预处理，这个预处理需要用 `A*`

#### 预处理

1. 从地图中随机采样一对点，这一对点的曼哈顿距离不太近，也不太远
2. 如果采样点有墙壁，弃去，重采
3. 利用 `A*` 或 `BFS`（如果距离不算远）计算这一对点的真实距离
4. 重复以上过程 $k$ 次

为了找到较好的 `k`，我们要推导一下

*TIPS 只能算是定性了...因为 IDA\* 等算法的平均复杂度是极难估计的...*

1. 经过模拟，对于 $N\times N$ 的地图，完全随机采样的期望曼哈顿距离约为 $0.7N$
2. 据估算，推箱子的分支因子是 $10<\gamma<30$
3. 利用 `A*` 搜索到期望搜索深度 $d$ 的最坏时间复杂度 $O(\gamma^d)$ 
4. 假设搜索路径深度就是两点之间的曼哈顿距离，我们得到 `A*` 时间复杂度 $O(k\gamma^{0.7N})$
5. 查阅一些资料，不妨假定总的搜索算法的时间复杂度近似是 $O(\frac{\gamma^{40}}{\log k})$，总体时间复杂度就是 $O(k\gamma^{0.7N}+\frac{\gamma^{40}}{\log k})$
6. 注意到 $0.7N<40$，时间复杂度主要由后一项决定，$k+\frac{a}{\log k}$ 最小值点会很大
7. 因此，在谜题比较复杂时，$k$ 可以取得尽量大，可以通过经验实验进一步确定 

暂时还没有进行实验，对于简单小地图谜题可以先使用 $k=5$，复杂大地图谜题可以使用 $k=20$

#### 正式计算

假定对于两个点 `A` `B`，使用以下算法估计 `A` 和 `B` 之间的距离：

1. 分别找到离 `A` `B` 两点最近的采样点 `A'` `B'`
2. 计算曼哈顿距离 $d(A,A')+d(B,B')$，然后加上预先计算好的采样点距离 $d(A',B')$
3. 结果就是 `A` `B` 两点的近似距离
4. 如果需要平滑，可以和 `A` `B` 两点之间的曼哈顿距离做加权平均

#### 为什么能凑效？

这个算法基于一个重要的假设：**一对比较近的点，其曼哈顿距离对真实距离的近似程度，总是高于一对比较远的点，其曼哈顿距离对真实距离的近似程度**

---

## 并行松弛分层搜索

这个算法吸收了**拉箱子优化**，**松弛优化**以及**蒙特卡洛法**的想法

### 基本步骤

1. 设置当前推箱子地图状态为所有箱子都在目标点
2. 生成 $k_0$ 个新状态，相对于当前状态，每个状态都进行一次箱子的一定距离随机位移
3. 在特定限时 $T$ 或最高代价 $L$ 内并行执行 `IDA*`，找到每个状态到达原状态的路径解
4. 如果没有解，放宽 $T$ 和 $L$ 重复执行，或者当 $T$ 和 $L$ 已经很大的时候，放弃寻找，转到第 7 步
5. 对于求出解的所有状态，评估当前局面 -> 所有箱子初始局面最小代价并排序
6. 基于求出解的状态，再次进行箱子的一定距离随机位移，共生成 $k_{n+1}\le k_{n}^2$ 个状态，重复 2 ~ 5 步
7. 如果状态总数即将超出并行核心数量，停止生成，每个核心独立进行 `IDA*` 搜索
8. 如果有核心到达了箱子初始局面，报告主程序，遍历生成最终路径返回

依然基于一个假设：

****